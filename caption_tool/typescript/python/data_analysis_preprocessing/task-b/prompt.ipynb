{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from IPython.display import Image, display, Audio, Markdown\n",
    "import base64\n",
    "\n",
    "# Preview image for context\n",
    "\n",
    "# OpenAI API 키 설정\n",
    "openai.api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_num):\n",
    "    \"\"\"\n",
    "    @description\n",
    "    주어진 경로에서 JSON 파일을 불러와 오브젝트를 추출하는 함수\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        IMAGE_PATH = f\"C:\\\\workplace\\\\Kilab\\\\etri\\\\dataset\\\\취합\\\\평가셋\\\\images for Task-B\\\\boxedImage{file_num}.jpg\"\n",
    "        display(Image(IMAGE_PATH))\n",
    "        with open(IMAGE_PATH, \"rb\") as image_file:\n",
    "            base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    except :\n",
    "        base64_image = \"\"\n",
    "    \n",
    "    object_list=[]\n",
    "    try :\n",
    "        file_path =f'C:\\\\workplace\\\\Kilab\\\\git\\\\caption_tool\\\\typescript\\\\front\\\\public\\\\json\\\\outputJson\\\\output_{file_num}.json'\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # 박스를 캡션 수를 기준으로 내림차순\n",
    "        sorted_boxes = sorted(data['new_bounding_boxes'],key=lambda x: len(x['captions']), reverse=True)\n",
    "        # 전체 박스 개수\n",
    "        print(\"number of box:\", len(sorted_boxes))\n",
    "        # 박스 개수 8개 이하로 줄이기\n",
    "        if len(sorted_boxes)>8: sorted_boxes = sorted_boxes[:7]\n",
    "        # print(sorted_boxes)\n",
    "        \n",
    "        # 박스 후처리\n",
    "        # 원래 region 별 캡션 리스트 정보(캡션/region_id)\n",
    "        # region_descriptions_list = data[list(data.keys())[0]]['region_descriptions_list']\n",
    "        # # region_id로 매핑할 정보들\n",
    "        # new_all_regions = data[list(data.keys())[0]]['new_all_regions']\n",
    "        \n",
    "        # 캡션 내 키워드 추출\n",
    "       \n",
    "        for box in sorted_boxes:\n",
    "            # object_list에 빈 리스트 추가\n",
    "            object_list.append([])\n",
    "            # 캡션 세트 리스트 가져오기\n",
    "            for captions in box['captions']:\n",
    "                correct_keywords= [item.lower() for item in captions['caption'].split(' ') if item not in captions['errorCaption'][0].split(' ')]\n",
    "                [object_list[-1].append(correct_keyword) for correct_keyword in correct_keywords] \n",
    "            # break\n",
    "            # captions = [captions['caption'] for captions in box['captions']]\n",
    "            # # print(\"correct captions of box:\", captions)\n",
    "            # for caption in captions:\n",
    "            #     region_id_list = [region_descriptions['region_id'] for region_descriptions in region_descriptions_list if region_descriptions['phrase'].lower().strip()==caption.lower().strip()]\n",
    "            #     for region_id in region_id_list:\n",
    "            #         for region in new_all_regions:\n",
    "            #             if region['region_id']==region_id:\n",
    "            #                 # print(\"3\")\n",
    "            #                 observed_objects = region['synsets']\n",
    "            #                 if len(observed_objects) > 0 : \n",
    "            #                     if isinstance(observed_objects[0], dict):\n",
    "            #                         observed_objects = [observed_object['synset_name'] for observed_object in observed_objects]\n",
    "                            \n",
    "            #                 [object_list[-1].append(observed_object) for observed_object in observed_objects] \n",
    "            #                 print\n",
    "            #                 break\n",
    "\n",
    "        \n",
    "    except :\n",
    "        print(\"json 데이터 읽는 중 오류 발생\")\n",
    "    finally :\n",
    "        object_list = [list(set(objects)) for objects in object_list]\n",
    "        print(object_list)\n",
    "        return object_list, base64_image\n",
    "load_data(1160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paragraph(file_num, model=\"gpt-4o-mini\", temperature=0):\n",
    "    \"\"\"\n",
    "    @description\n",
    "    주어진 입력 데이터에 기반하여 GPT 모델을 통해 추론을 생성하는 함수\n",
    "    \"\"\"\n",
    "    # 오브젝트 리스트 + 이미지 뽑아내기\n",
    "    object_list, base64_image = load_data(file_num)\n",
    "    \n",
    "    # 프롬프트 생성\n",
    "    # 이미지의 오브젝트간 연관성을 기준으로 큰 범위의 바운딩박스를 생성 \n",
    "    objects = [ f\"box{index}: {objects}\" for index, objects in enumerate(object_list)]\n",
    "    prompt = (\n",
    "        f\"\"\"\n",
    "        Based on the given image, Create a large range of bounding boxes based on the correlation between regions in the image.\n",
    "        the large range of bounding boxes according to the following rules and create a paragraph for each large region. \n",
    "        Each paragraph should be within 40 words. Provide 2-3 examples as shown below.\n",
    "        \"Be careful not to describe each original region individually.\"\n",
    "        \n",
    "        \n",
    "        [Region selection rules]\n",
    "\n",
    "        Perspective\n",
    "        Object-oriented\n",
    "        Prioritize highly related objects\n",
    "        Distinguish unique points of the image\n",
    "        Adjust prompt complexity based on difficulty\n",
    "        \n",
    "        [Objects observed in the image]\n",
    "        {objects}\n",
    "            \n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # GPT 모델에 요청\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a intelligent AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\":\"text\",\"text\":prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "                ]\n",
    "             }\n",
    "        ],\n",
    "        max_tokens=200,\n",
    "        n=1,\n",
    "        # stop=None,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# 평가 데이터 파일 경로\n",
    "# 결과 저장을 위한 리스트 초기화\n",
    "\n",
    "    \n",
    "def save_json(file_num):\n",
    "    \"\"\"\n",
    "    @description\n",
    "    generate_paragraph를 호출해 받아온 데이터를 JSON 파일로 저장하는 함수\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate_paragraph 호출\n",
    "    # 이미지에 대한 답 생성\n",
    "    result = \"\"\n",
    "    result = generate_paragraph(file_num)\n",
    "    print(f\"예제 ID: {file_num}, GPT 결과: {result}\")\n",
    "    \n",
    "    # 데이터 생성\n",
    "    # 기존 output 데이터 + paragraph 키 붙임\n",
    "    data={}\n",
    "    try :\n",
    "        file_path =f'C:\\\\workplace\\\\Kilab\\\\git\\\\caption_tool\\\\typescript\\\\front\\\\public\\\\json\\\\outputJson\\\\output_{file_num}.json'\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "    except :\n",
    "        print(\"json 데이터 읽는 중 오류 발생\")\n",
    "    finally :\n",
    "        data['paragraph']={'gpt_version':result,\n",
    "                           'annotator_version':result}\n",
    "        \n",
    "        \n",
    "    with open(f'paragraph{file_num}.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "file_list = [1160, 1161, 1162,1164,1166,1167,1180,1168,1277,1279]\n",
    "file_num = 2100\n",
    "[save_json(file_num) for file_num in file_list]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
