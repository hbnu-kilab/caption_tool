{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어가 \"\"로 바뀌거나 correct-error\n",
    "### 돌리는 순서: update_wrong_error > ethics > coredata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import traceback\n",
    "\n",
    "# 경로 설정\n",
    "# 본인 outputJson 폴더 위치\n",
    "outputJson= \"C:\\\\workplace\\\\Kilab\\\\etri\\\\dataset\\\\취합\\\\평가셋\\\\003_KILab 재검수\\\\003_전체\\\\\"\n",
    "# outputJson = \"C:\\\\workplace\\\\Kilab\\\\git\\\\caption_tool\\\\typescript\\\\front\\\\public\\\\json\\\\outputJson\\\\\"\n",
    "# outputJson = \"C:\\\\workplace\\\\Kilab\\\\etri\\\\dataset\\\\취합\\\\학습셋\\\\002_에러캡션 완료\\\\all\\\\\" # 학습셋\n",
    "# output_path = f\"C:\\\\workplace\\\\Kilab\\\\etri\\\\dataset\\\\취합\\\\평가셋\\\\003_KILab 재검수\\\\003_전체\\\\\"\n",
    "\n",
    "\n",
    "\n",
    "def filter_prepositions_and_articles(word_list):\n",
    "    \"\"\"\n",
    "    @description\n",
    "    리스트 내 단어에서 전치사 및 관사 제거\n",
    "    find_diff_and_compound에서 사용용\n",
    "\n",
    "    \"\"\"\n",
    "# 전치사와 관사 목록\n",
    "    prepositions = {\n",
    "        \"in\", \n",
    "        \"on\", \n",
    "        \"at\", \n",
    "        \"by\", \n",
    "        \"with\", \n",
    "        \"with in\", \n",
    "        \"within\", \n",
    "        \"about\",\n",
    "        \"against\",\n",
    "        \"between\",\n",
    "        \"into\",\n",
    "        \"in to\",\n",
    "        \"through\",\n",
    "        \"during\",\n",
    "        \"before\",\n",
    "        \"after\",\n",
    "        \"above\",\n",
    "        \"below\",\n",
    "        \"to\",\n",
    "        \"from\",\n",
    "        \"up\",\n",
    "        \"down\",\n",
    "        \"for\",\n",
    "        \"over\",\n",
    "        \"under\",\n",
    "        \"again\",\n",
    "        \"further\",\n",
    "        \"off\",\n",
    "        \"near\",\n",
    "    }\n",
    "    articles = {\"a\", \"an\", \"the\"}\n",
    "\n",
    "    # 각 구에서 전치사 및 관사 제거\n",
    "    filtered_phrases = []\n",
    "    for phrase in word_list:\n",
    "        words = re.findall(r\"\\w+\", phrase.lower())  # 각 구를 단어로 분리 (소문자 처리)\n",
    "        words = phrase.split()  # 단어로 분리\n",
    "\n",
    "        if words[0].lower() in prepositions:  # 첫 단어가 전치사면\n",
    "            words = words[1:]  # 전치사 제거\n",
    "\n",
    "        filtered_words = [word for word in words if word not in articles]\n",
    "        filtered_phrases.append(\" \".join(filtered_words))\n",
    "\n",
    "    return filtered_phrases\n",
    "\n",
    "def find_diff_and_compound(correct, error):\n",
    "    \"\"\"\n",
    "    @description\n",
    "    correct, error caption을 비교하여 달라진 부분 추출(복합명사 살려서)\n",
    "\n",
    "    \"\"\"\n",
    "    # Step 1: 문장을 단어 리스트로 분리 (공백 및 구두점 처리)\n",
    "    error_words = re.findall(r\"\\w+\", error.lower())  # 문장1의 단어 목록 (소문자 처리)\n",
    "    correct_words = re.findall(\n",
    "        r\"\\w+\", correct.lower()\n",
    "    )  # 문장2의 단어 목록 (소문자 처리)\n",
    "\n",
    "    # Step 2: 겹치는 단어 제거\n",
    "    # 리스트의 요소 개수를 세기\n",
    "    counter1 = Counter(error_words)\n",
    "    counter2 = Counter(correct_words)\n",
    "\n",
    "    common_words = counter1 & counter2  # 겹치는 단어 목록\n",
    "    # 공통 단어를 제외한 error_words의 고유 단어들\n",
    "    unique_error_words = list((counter1 - common_words).elements())\n",
    "\n",
    "    # 공통 단어를 제외한 correct_words의 고유 단어들\n",
    "    unique_correct_words = list((counter2 - common_words).elements())\n",
    "\n",
    "    # Step 3: 겹치지 않는 단어들 중에서 문장에서 붙어 있는 단어 찾기\n",
    "    def find_compound_nouns(words, original_sentence):\n",
    "        compounds = []\n",
    "        i = 0\n",
    "        while i < len(words):\n",
    "            # 복합 명사 조합을 체크\n",
    "            found_compound = False\n",
    "            for j in range(len(words), 0, -1):  # len(words)개까지 조합 가능하도록\n",
    "                if i + j <= len(words):\n",
    "                    compound_candidate = \" \".join(words[i : i + j])\n",
    "                    if compound_candidate in original_sentence:\n",
    "                        compounds.append(compound_candidate)\n",
    "                        i += j  # 조합한 단어 개수만큼 인덱스 증가\n",
    "                        found_compound = True\n",
    "                        break\n",
    "            if not found_compound:  # 복합 명사가 아닐 경우\n",
    "                compounds.append(words[i])\n",
    "                i += 1\n",
    "        return compounds\n",
    "\n",
    "    # 문장1과 문장2에서 각각 복합 명사 추출\n",
    "    human_annotation = find_compound_nouns(unique_error_words, error.lower())\n",
    "    correct_keyword = find_compound_nouns(unique_correct_words, correct.lower())\n",
    "    filtered_human_annotation = filter_prepositions_and_articles(human_annotation)\n",
    "    filtered_correct_keyword = filter_prepositions_and_articles(correct_keyword)\n",
    "\n",
    "\n",
    "    # 최종 차이점 리스트\n",
    "    return filtered_human_annotation, filtered_correct_keyword\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def load_wrong_data(file_num):\n",
    "    \"\"\"\n",
    "    @description\n",
    "    주어진 경로에서 JSON 파일을 불러와 비윤리적 단어로 변경되었을 가능성이 있는 데이터 확인\n",
    "    \"\"\"\n",
    "    try :\n",
    "        file_path = outputJson+f'output_{file_num}.json'\n",
    "        print(os.path.exists(file_path))\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # 박스를 캡션 수를 기준으로 내림차순\n",
    "        sorted_boxes = sorted(data['new_bounding_boxes'],key=lambda x: len(x['captions']), reverse=True)\n",
    "       \n",
    "        for box in sorted_boxes:\n",
    "            # 캡션 세트 리스트 가져오기\n",
    "            for captions in box['captions']:\n",
    "                if captions['errorCaption'] == [] or \"time reads 6:05 pm\" in captions['errorCaption'][0]:\n",
    "                    return file_num\n",
    "                elif captions['caption'] == captions['errorCaption'][0]:\n",
    "                    print(f\"correct-error 값이 같음: {file_num}\")\n",
    "                    return file_num\n",
    "                elif bool(re.search(r'[\\uAC00-\\uD7A3]', captions['errorCaption'][0])):\n",
    "                    print(file_num,\":\", captions['errorCaption'][0])\n",
    "                    return file_num\n",
    "                \n",
    "                errors, corrects = find_diff_and_compound(captions['caption'], captions['errorCaption'][0])  \n",
    "                if errors == []:\n",
    "                    print(captions['caption'], captions['errorCaption'][0], file_num)\n",
    "                    return file_num\n",
    "    except :\n",
    "        print(\"json 데이터 읽는 중 오류 발생::\", traceback.format_exc())\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "1702 : black tinted window on 버스\n",
      "True\n",
      "1702 : black tinted window on 버스\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "green bug sticker on the keyboard of the macbook green bug on the keyboard of the macbook 1796\n",
      "True\n",
      "green bug sticker on the keyboard of the macbook green bug on the keyboard of the macbook 1796\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "correct-error 값이 같음: 1806\n",
      "True\n",
      "correct-error 값이 같음: 1806\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "correct-error 값이 같음: 1822\n",
      "True\n",
      "correct-error 값이 같음: 1822\n",
      "[1702, 1796, 1806, 1822]\n"
     ]
    }
   ],
   "source": [
    "# wrong_data = [load_wrong_data(num) for num in range(779,1175) if load_wrong_data(num)!=None] # <--완료 송강현 549~778\n",
    "wrong_data = [load_wrong_data(num) for num in range(1559,1823) if load_wrong_data(num)!=None] # 송강현 549~778\n",
    "# wrong_data = [i for i in wrong_data]\n",
    "print(wrong_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1702\n",
      "1796\n",
      "1806\n",
      "바뀐 에러: the ball is yellow \n",
      " the dice is yellow\n",
      "바뀐 에러: it is a green ball \n",
      " it is a green dice\n",
      "완전일치 - 안바뀜: the w is pink\n",
      "완전일치 - 안바뀜: nose\n",
      "바뀐 에러: left hand displayed upright. \n",
      " left Handkerchief displayed upright.\n",
      "바뀐 에러:  Front side of image there is a pole \n",
      " front side of image there is a pipe\n",
      "1822\n",
      "바뀐 에러:  Background of image there are few plants \n",
      "  Background of image there are few plants\n",
      "바뀐 에러:  Bottom of image is a grassy land \n",
      "  Bottom of image is a grassy land\n"
     ]
    }
   ],
   "source": [
    "from error_dict import dictionary \n",
    "\n",
    "# 대체어 그룹 정의\n",
    "def merge_dicts(*dicts):\n",
    "    merged_dict = {}\n",
    "    for dictionary in dicts:\n",
    "        for key, value in dictionary.items():\n",
    "            if key in merged_dict:\n",
    "                print(key, value)\n",
    "                merged_dict[key].extend(value)\n",
    "            else:\n",
    "                merged_dict[key] = value\n",
    "    return merged_dict\n",
    "\n",
    "replacement_groups = merge_dicts(dictionary)\n",
    "\n",
    "# 정규 표현식 패턴 생성\n",
    "replacement_patterns = {\n",
    "    replacement: re.compile(r\"\\b\" + r\"\\b|\\b\".join(re.escape(term) for term in terms) + r\"\\b\", re.IGNORECASE)\n",
    "    for replacement, terms in replacement_groups.items()\n",
    "}\n",
    "\n",
    "# JSON 파일 읽기\n",
    "for i in wrong_data:# wrong_data: # (각자 구축량 시작점, 각자 구축량 마감개수 + 1) \n",
    "    file_path = outputJson+f'output_{i}.json'\n",
    "    print(i)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    new_bounding_boxes = data.get('new_bounding_boxes', [])\n",
    "\n",
    "    for box_index, box in enumerate(new_bounding_boxes):\n",
    "        for caption_idx, caption in enumerate(box['captions']):\n",
    "            if caption['errorCaption'] == []:\n",
    "                new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'] = [caption['caption'].lower().strip()]\n",
    "                for replacement, pattern in replacement_patterns.items():\n",
    "                    if pattern.search(caption['caption'].lower().strip()):\n",
    "                        new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'] = [pattern.sub(replacement, new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'][0])]\n",
    "                        \n",
    "                if new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'][0] == caption['caption'].lower().strip():\n",
    "                    print(f'에러없음 - 안바뀜:', new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'])\n",
    "                else:\n",
    "                    print(f'채운 에러:', new_bounding_boxes[box_index]['captions'][caption_idx]['caption'], \"\\n\", new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'])\n",
    "            else:\n",
    "                for errorCaption_idx, errorCaption in enumerate(caption['errorCaption']):\n",
    "                    correct_caption = caption['caption'].lower().strip()\n",
    "                    error_caption = errorCaption.lower().strip()\n",
    "                    '''완전 일치'''\n",
    "                    if caption['caption'].lower().strip() == errorCaption.lower().strip():\n",
    "                        for replacement, pattern in replacement_patterns.items():\n",
    "                            if pattern.search(error_caption):\n",
    "                                # 대체어로 변경\n",
    "                                new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'][errorCaption_idx] = pattern.sub(replacement, error_caption)\n",
    "                                break\n",
    "                        if new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'][errorCaption_idx] == error_caption:\n",
    "                            print(f'완전일치 - 안바뀜:',new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'][errorCaption_idx])\n",
    "                        else:\n",
    "                            print(f'바뀐 에러:', new_bounding_boxes[box_index]['captions'][caption_idx]['caption'], \"\\n\", new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'][0])\n",
    "                            \n",
    "                    else:\n",
    "                        errors, corrects = find_diff_and_compound(correct_caption, error_caption) \n",
    "                        # print(errors)\n",
    "                        '''공백이 들어간 경우'''\n",
    "                        if errors == []:\n",
    "                            for replacement, pattern in replacement_patterns.items():\n",
    "                                if pattern.search(caption['caption'].lower().strip()) is None:\n",
    "                                    new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'][errorCaption_idx] = pattern.sub(replacement, correct_caption)\n",
    "                                    break\n",
    "                                    # print(f'바뀜: {new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'][errorCaption_idx]}')\n",
    "                            if new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'][errorCaption_idx] == [correct_caption]:\n",
    "                                print(f'공백이 들어감 - 안바뀜: {errorCaption}')\n",
    "                        # else:\n",
    "                        #     if \"time reads 6:05 pm\" in error_caption:\n",
    "                        #         new_bounding_boxes[box_index]['captions'][caption_idx]['errorCaption'][0] = caption['caption']\n",
    "\n",
    "    data['new_bounding_boxes'] = new_bounding_boxes\n",
    "    \n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core 데이터 업데이트 확인\n",
    "core_path=\"C:\\\\workplace\\\\Kilab\\\\etri\\\\dataset\\\\취합\\\\학습셋\\\\003_core 데이터 배포 버전\\\\all\\\\\"\n",
    "\n",
    "import json\n",
    "for file_num in range(8744,11365):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open(core_path+f\"core_{file_num}.json\",'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        key = list(data.keys())[0]\n",
    "        regions = data[key]['regions']\n",
    "        unprocessed_keywords = data[key]['unprocessed_keywords']\n",
    "        for region in regions:\n",
    "            captions = region['captions']\n",
    "            for caption_pairs in captions:\n",
    "                if \"time reads 6:05 pm\" in caption_pairs['counterfactual_caption'] and \"time reads 6:05 pm\" != caption_pairs['counterfactual_caption']:\n",
    "                    print(\"file = \", file_num)\n",
    "                    print(\"ㅈ됨: \",caption_pairs['counterfactual_caption'])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
